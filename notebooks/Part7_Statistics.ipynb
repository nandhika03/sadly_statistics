{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a44372",
   "metadata": {},
   "source": [
    "# **The Bell Shaped Curve**\n",
    "\n",
    "- The understanding about the normal curve is very crucial for inferential statistics which roots from probability\n",
    "- We should also state the confidence with which we say the occurence of a particular event.\n",
    "- The curve is a visual representation of a particular type of distribution\n",
    "\n",
    "### **Characteristics of a normal curve**\n",
    "\n",
    "- The mean, median and mode are equal\n",
    "- The curve is symmetrical about the mean \n",
    "- The two tails of the distribution are asymptotic in nature, meaning that they smoothen around the x-axis, but never touch the x-axis.\n",
    "- This implies an very important point that we should always be open for extreme values in nature.\n",
    "- It also denotes that there is an infinitesimally small probability that extreme scores might occur.\n",
    "\n",
    "### **Area under the curve and probability**\n",
    "\n",
    "- We always make sure that a sample taken from a population follows a normal distribution\n",
    "- Because it is what is the most commonly found distribution in nature\n",
    "- The scores/ values in the middle of the distribution have high chances of occuring (high probability)\n",
    "- The mean of a standard normal distribution is 0 and the standard deviation is 1\n",
    "- The area under the curve represents the probability of a score occuring there\n",
    "- The standard deviation in a normal distribution is calculated and when taken as the number of standard deviations, we can say that 68.2% of scores fall between 1 standard deviation from mean (-1,1).\n",
    "- 95.4% of scores fall between 2 standard deviation from mean (-2,2).\n",
    "- 99.7% of scores fall between 1 standard deviation from mean (-3,3).\n",
    "- So we can simply saw that almost 100% of values lie between the -3,3 standard deviations of the distribution in a normal distribution\n",
    "\n",
    "### **Z score**\n",
    "\n",
    "- Every distrubution can have different values, hence a standard score would be better to compare those distributions with one another.\n",
    "- Hence, we introduce a measure called z-score which is better than standard deviation\n",
    "- Z = (Raw score - Mean) / Standard deviation or [ Number of standard deviations away from the mean]\n",
    "- We can compute the raw score by knowing the mean and standard deviation and the z-score.\n",
    "- When raw score > mean, then z score >0\n",
    "- When raw score < mean, then z score <0\n",
    "- We can compare the z-scores of different distributions\n",
    "- The area under the curve between a particular z-score and mean would give the probability of the score occuring there\n",
    "- There are other standardized scores such as T score = Zx10 +50\n",
    "- T score is rarely negative\n",
    "- Standardized scores : comes from a distribution with pre-defined mean and standard deviation\n",
    "\n",
    "### **Hypothesis and Z score**\n",
    "\n",
    "- The likelihood that no heads occur in 10 tosses cannot be attributed as chance. There might be some bias in the coin\n",
    "- This gives way to think that if the probability of a score occuring is just less than 5% (human defined threshold) then its occurence cannot be just by nature, but some external factor (variables, treatment) should have induced it.\n",
    "- In the null hypothesis, we say that there is no difference between this and that or there is no relationship between X and Y\n",
    "- There will be no relationship if the values fall in the normal distribution (within the 99.7% area)\n",
    "- But when the scores fall in the area where the probability is less than 5%, then there must be some significant reason causing this and that is why we reject the null hypothesis and bring in the research hypothesis\n",
    "\n",
    "### **Normal Curve and its friends**\n",
    "\n",
    "How other distributions differ from the normal distribution\n",
    "\n",
    "#### **Average**\n",
    "- The normal curves can have different means\n",
    "\n",
    "#### **Variability**\n",
    "- The variability can also change. If it is more skinny then the variability is less, if it is fat, then the variability is more\n",
    "\n",
    "#### **Skewness**\n",
    "- The normal distribution has zero skew\n",
    "- If the right tail is elongated it is positively skewed, meaning it has more values falling on the left side \n",
    "- If the left tail is elongated it is negatively skewed, meaning it has more values falling on the right side \n",
    "- The Pearson's measure of skewness = 3(mean-median)\n",
    "\n",
    "#### **Kurtosis**\n",
    "- Kurtosis talks about how many outliers are in the distribution\n",
    "  - Leptokurtic : It is very tall and has a bump; the number of outliers is more\n",
    "  - Mesokurtic : kurtosis = 0, normal distribution\n",
    "  - Platykurtic: It is very flat and short; the number of common values is more\n",
    "\n",
    "### **Statistical Significance**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
